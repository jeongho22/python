{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27be34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "plt.rc(\"font\", family=font_name)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9679f",
   "metadata": {},
   "source": [
    "# 1. XOR 문제\n",
    "\n",
    "\n",
    "### (1) OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "787e41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],\n",
    "                  [1,0,0],[1,1,0],[1,0,1],[1,1,1]],dtype=np.float32) # 8,3\n",
    "\n",
    "\n",
    "y_data = np.array([[0],[1],[1],[1],[1],[1],[1],[1]],dtype=np.float32) #8,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "079ad42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쉐잎채워넣기\n",
    "\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[8,3])\n",
    "y= tf.placeholder(tf.float32, shape=[8,1])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1]),tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]),tf.float32, name=\"bias\")\n",
    "\n",
    "\n",
    "# 가설\n",
    "\n",
    "hypot = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "# 비용 # sigmoid에 비용구하는 공식\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypot)+(1 - y)*tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "\n",
    "train =tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b23eda7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설: [[0.40529573]\n",
      " [0.9153195 ]\n",
      " [0.9001018 ]\n",
      " [0.99305105]\n",
      " [0.8867514 ]\n",
      " [0.99043256]\n",
      " [0.9920122 ]\n",
      " [0.9993913 ]]\n",
      "예측: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "## 세션 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds= tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y),dtype=tf.float32))\n",
    "\n",
    "for step in range(1000):\n",
    "    _,h,p,a = sess.run([train,hypot,preds,accuracy],feed_dict={X:X_data,y:y_data})\n",
    "\n",
    "print(\"가설:\",h)\n",
    "print(\"예측:\",p)\n",
    "print(\"정확도\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a462898",
   "metadata": {},
   "source": [
    "# 2. AND GATE\n",
    "\n",
    "#### 모두가 참이여야함.. 앤드는 그래서 다 00000으로해줘야함 마지막 [111]은 1로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26ccb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],\n",
    "                  [1,0,0],[1,1,0],[1,0,1],[1,1,1]],dtype=np.float32) # 8,3\n",
    "\n",
    "\n",
    "y_data = np.array([[0],[0],[0],[0],[0],[0],[0],[1]],dtype=np.float32) #8,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0975c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.00603795]\n",
      " [0.03444421]\n",
      " [0.03664634]\n",
      " [0.18259871]\n",
      " [0.03183812]\n",
      " [0.17076561]\n",
      " [0.16185808]\n",
      " [0.5473717 ]]\n",
      "예측 :  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 쉐잎채워넣기\n",
    "\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[8,3])\n",
    "y= tf.placeholder(tf.float32, shape=[8,1])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1]),tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]),tf.float32, name=\"bias\")\n",
    "\n",
    "\n",
    "# 가설\n",
    "\n",
    "hypot = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용 # sigmoid에 비용구하는 공식\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "## 세션 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(1000):\n",
    "    _, h, p, a = sess.run([train, hypot, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84292473",
   "metadata": {},
   "source": [
    "# 3. XOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8320183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설: [[0.74574006]\n",
      " [0.75065625]\n",
      " [0.7485677 ]\n",
      " [0.7534473 ]\n",
      " [0.745396  ]\n",
      " [0.7482262 ]\n",
      " [0.7503166 ]\n",
      " [0.7531102 ]]\n",
      "예측: [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 0.75\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],\n",
    "                  [1,0,0],[1,1,0],[1,0,1],[1,1,1]],dtype=np.float32) # 8,3\n",
    "\n",
    "\n",
    "y_data = np.array([[0],[1],[1],[1],[1],[1],[1],[0]],dtype=np.float32) #8,1\n",
    "\n",
    "\n",
    "# 쉐잎채워넣기\n",
    "\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[8,3])\n",
    "y= tf.placeholder(tf.float32, shape=[8,1])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1]),tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]),tf.float32, name=\"bias\")\n",
    "\n",
    "\n",
    "# 가설\n",
    "\n",
    "hypot = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "# 비용 # sigmoid에 비용구하는 공식\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypot)+(1 - y)*tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "\n",
    "train =tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "## 세션 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds= tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y),dtype=tf.float32))\n",
    "\n",
    "for step in range(1000):\n",
    "    _,h,p,a = sess.run([train,hypot,preds,accuracy],feed_dict={X:X_data,y:y_data})\n",
    "\n",
    "print(\"가설:\",h)\n",
    "print(\"예측:\",p)\n",
    "print(\"정확도\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f7431",
   "metadata": {},
   "source": [
    "# 4) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51fc30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f55bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,1,0],[1,0,1],[1,1,1]] # 8,3\n",
    "\n",
    "\n",
    "y =[0,1,1,1,1,1,1,0] #8,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e898e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =svm.SVC(C=100).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef63c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "examples = [[0,0,0],[1,1,1],[0,1,0],[1,0,0],[1,1,0]]\n",
    "exam_label =[0,0,1,1,1]\n",
    "\n",
    "result = clf.predict(examples)\n",
    "print(result)\n",
    "\n",
    "# clf 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee91879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(exam_label,result)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e39dc",
   "metadata": {},
   "source": [
    "### (5) 딥러닝을 이용한 XOR\n",
    "\n",
    "\n",
    "### 인공신경망은 3계층으로 이루어져 있는데\n",
    "\n",
    "#### 입력계층\n",
    "#### 히든계층\n",
    "#### 출력계층 \n",
    "\n",
    "\n",
    "#### 히든 계층이 많아질수록 딥하다 한다.\n",
    "\n",
    "# 으로 나눌수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa41d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설: [[0.01760268]\n",
      " [0.99634415]\n",
      " [0.9864603 ]\n",
      " [0.9873922 ]\n",
      " [0.99402064]\n",
      " [0.9963304 ]\n",
      " [0.98538667]\n",
      " [0.0395295 ]]\n",
      "예측: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],\n",
    "                  [1,0,0],[1,1,0],[1,0,1],[1,1,1]],dtype=np.float32) # 8,3\n",
    "\n",
    "\n",
    "y_data = np.array([[0],[1],[1],[1],[1],[1],[1],[0]],dtype=np.float32) #8,1\n",
    "\n",
    "\n",
    "# 쉐잎채워넣기\n",
    "\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[None,3])\n",
    "y= tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "\n",
    "\n",
    "# 첫번째 hidden layer \n",
    "# 히든계층에서는 입력출력은 내마음대로 가능. 1부분을 맘대로 아무거나 숫자넣어도됌\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([3, 10]),tf.float32, name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random.normal([10]),tf.float32, name=\"bias1\")\n",
    "hypot1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "# 두번째 hidden layer \n",
    "# 히든계층에서는 입력출력은 내마음대로 가능. 1부분을 맘대로 아무거나 숫자넣어도됌\n",
    "# 하지만 마지막 히든 계층이라면 원래 출력 1이라고 해주면됌 8,3,8,1 -> 3,1 ->1\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([10, 1]),tf.float32, name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random.normal([1]),tf.float32, name=\"bias2\")\n",
    "##### hypot1 을 넣어줌으로써 조금더 학습하게 해줌.\n",
    "\n",
    "\n",
    "\n",
    "# 가설\n",
    "\n",
    "hypot = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "# 비용 # sigmoid에 비용구하는 공식\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypot)+(1 - y)*tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "\n",
    "train =tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "## 세션 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds= tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y),dtype=tf.float32))\n",
    "\n",
    "for step in range(10000):\n",
    "    _,h,p,a = sess.run([train,hypot,preds,accuracy],feed_dict={X:X_data,y:y_data})\n",
    "\n",
    "print(\"가설:\",h)\n",
    "print(\"예측:\",p)\n",
    "print(\"정확도\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f7238",
   "metadata": {},
   "source": [
    "### (6) deep& wide 다시 하기\n",
    "\n",
    "+ deep : 6개의 hidden layer\n",
    "+ wide : 각 계층의 입출력 갯수는 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6b8c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설: [[7.1150064e-04]\n",
      " [9.9969757e-01]\n",
      " [9.9980724e-01]\n",
      " [9.9958241e-01]\n",
      " [9.9967599e-01]\n",
      " [9.9978471e-01]\n",
      " [9.9968708e-01]\n",
      " [9.5328689e-04]]\n",
      "예측: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],\n",
    "                  [1,0,0],[1,1,0],[1,0,1],[1,1,1]],dtype=np.float32) # 8,3\n",
    "\n",
    "\n",
    "y_data = np.array([[0],[1],[1],[1],[1],[1],[1],[0]],dtype=np.float32) #8,1\n",
    "\n",
    "\n",
    "# 쉐잎채워넣기\n",
    "\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[None,3])\n",
    "y= tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "\n",
    "\n",
    "# 첫번째 hidden layer \n",
    "# 히든계층에서는 입력출력은 내마음대로 가능. 1부분을 맘대로 아무거나 숫자넣어도됌\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([3, 50]),tf.float32)\n",
    "b1 = tf.Variable(tf.random.normal([50]),tf.float32)\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "# 두번째 hidden layer \n",
    "# 히든계층에서는 입력출력은 내마음대로 가능. 1부분을 맘대로 아무거나 숫자넣어도됌\n",
    "# 하지만 마지막 히든 계층이라면 원래 출력 1이라고 해주면됌 8,3,8,1 -> 3,1 ->1\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([50, 50]),tf.float32)\n",
    "b2 = tf.Variable(tf.random.normal([50]),tf.float32)\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "\n",
    "# 세번째 hidden layer\n",
    "W3 = tf.Variable(tf.random.normal([50, 50]), tf.float32)\n",
    "b3 = tf.Variable(tf.random.normal([50]), tf.float32)\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "# 네번째 hidden layer\n",
    "W4 = tf.Variable(tf.random.normal([50, 50]), tf.float32)\n",
    "b4 = tf.Variable(tf.random.normal([50]), tf.float32)\n",
    "layer4 = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "# 다섯번째 hidden layer\n",
    "W5 = tf.Variable(tf.random.normal([50, 50]), tf.float32)\n",
    "b5 = tf.Variable(tf.random.normal([50]), tf.float32)\n",
    "layer5 = tf.sigmoid(tf.matmul(layer4, W5) + b5)\n",
    "\n",
    "# 여섯번째 hidden layer\n",
    "W6 = tf.Variable(tf.random.normal([50, 1]), tf.float32)\n",
    "b6 = tf.Variable(tf.random.normal([1]), tf.float32)\n",
    "hypot = tf.sigmoid(tf.matmul(layer5, W6) + b6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 비용 # sigmoid에 비용구하는 공식\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypot)+(1 - y)*tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "\n",
    "train =tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "## 세션 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds= tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y),dtype=tf.float32))\n",
    "\n",
    "for step in range(10000):\n",
    "    _,h,p,a = sess.run([train,hypot,preds,accuracy],feed_dict={X:X_data,y:y_data})\n",
    "\n",
    "print(\"가설:\",h)\n",
    "print(\"예측:\",p)\n",
    "print(\"정확도\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcf754",
   "metadata": {},
   "source": [
    "# 2. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d98329f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_28772/1497151228.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "가설: [[0.02025673]\n",
      " [0.9964194 ]\n",
      " [0.99655545]\n",
      " [0.98851085]\n",
      " [0.9870846 ]\n",
      " [0.9908408 ]\n",
      " [0.9896204 ]\n",
      " [0.0329448 ]]\n",
      "예측: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],\n",
    "                  [1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 첫번째 hidden layer\n",
    "W1 = tf.Variable(tf.random.normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random.normal([10]), tf.float32, name=\"bias1\")\n",
    "hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# 두번째 hidden layer\n",
    "W2 = tf.Variable(tf.random.normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random.normal([1]), tf.float32, name=\"bias2\")\n",
    "hypot = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "tf.summary.histogram(\"weight2\", W2)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 세션 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha01\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot, preds, accuracy, merged_summary], feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8700608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설: [[0.01840186]\n",
      " [0.998844  ]\n",
      " [0.99178153]\n",
      " [0.987937  ]\n",
      " [0.9920126 ]\n",
      " [0.9912484 ]\n",
      " [0.99105215]\n",
      " [0.02985647]]\n",
      "예측: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "##### tensorboard --logdir=log_dir2/alpha01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],\n",
    "                  [1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 첫번째 hidden layer\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random.normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "    b1 = tf.Variable(tf.random.normal([10]), tf.float32, name=\"bias1\")\n",
    "    hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"bias1\", b1)\n",
    "    tf.summary.histogram(\"hypot1\", hypot1)\n",
    "\n",
    "# 두번째 hidden layer\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random.normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "    b2 = tf.Variable(tf.random.normal([1]), tf.float32, name=\"bias2\")\n",
    "    hypot = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "    \n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias2\", b2)\n",
    "    tf.summary.histogram(\"hypot\", hypot)\n",
    "\n",
    "# 비용\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)    \n",
    "\n",
    "# 세션 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha01\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot, preds, accuracy, merged_summary], \n",
    "                             feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3139e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.6541478 ]\n",
      " [0.7360572 ]\n",
      " [0.7999494 ]\n",
      " [0.7978604 ]\n",
      " [0.79025316]\n",
      " [0.7636155 ]\n",
      " [0.78041905]\n",
      " [0.69230616]]\n",
      "예측 :  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 :  0.75\n"
     ]
    }
   ],
   "source": [
    "##### learning_rate = 0.01로 변경\n",
    "##### tensorboard --logdir=log_dir2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],\n",
    "                  [1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 첫번째 hidden layer\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random.normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "    b1 = tf.Variable(tf.random.normal([10]), tf.float32, name=\"bias1\")\n",
    "    hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"bias1\", b1)\n",
    "    tf.summary.histogram(\"hypot1\", hypot1)\n",
    "\n",
    "# 두번째 hidden layer\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random.normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "    b2 = tf.Variable(tf.random.normal([1]), tf.float32, name=\"bias2\")\n",
    "    hypot = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "    \n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias2\", b2)\n",
    "    tf.summary.histogram(\"hypot\", hypot)\n",
    "\n",
    "# 비용\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)    \n",
    "\n",
    "# 세션 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha001\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot, preds, accuracy, merged_summary], \n",
    "                             feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8809c4ff",
   "metadata": {},
   "source": [
    "# 3. ReLU : Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48d36bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/573112219.py:2: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/573112219.py:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data1/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data1/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data1/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data1/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)\n",
    "mnist =input_data.read_data_sets(\"data1/mnist/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffba494",
   "metadata": {},
   "source": [
    "# 1) 단순모델 89.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe234656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/4062311721.py:1: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/4062311721.py:14: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([28*28, 10]))\n",
    "b = tf.Variable(tf.random.normal([10]))\n",
    "\n",
    "# 가설, 비용\n",
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y)\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3dc406",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.argmax(hypot, 1)\n",
    "correct = tf.equal(preds,tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cadf231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/1737202594.py:4: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/1737202594.py:5: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "274 1831.9609852981569\n",
      "274 933.2773417524854\n",
      "274 903.0895150479406\n",
      "274 757.1150026633522\n",
      "274 845.7635638982599\n",
      "274 804.9692537064988\n",
      "274 735.4643819912995\n",
      "274 761.3179380104755\n",
      "274 760.7246243563565\n",
      "274 735.2570615456325\n",
      "274 740.5370648748221\n",
      "274 709.1971677468039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26436/1737202594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         _, c = sess.run([train, tf.reduce_mean(cost)], \n\u001b[1;32m---> 17\u001b[1;33m                         feed_dict={X:mnist.train.images, y:mnist.train.labels})\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### mini batch\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 30\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309365f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fd608",
   "metadata": {},
   "source": [
    "## (2) 딥러닝 모델\n",
    "\n",
    "+ Deep : layer 7개\n",
    "+ Wide : 계층간 입출력 갯수는 256개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee7e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 10])\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.Variable(tf.random.normal([28*28, 256]))\n",
    "b1 = tf.Variable(tf.random.normal([256]))\n",
    "logit1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logit1)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.Variable(tf.random.normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random.normal([256]))\n",
    "logit2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logit2)\n",
    "\n",
    "# Layer3\n",
    "W3 = tf.Variable(tf.random.normal([256, 256]))\n",
    "b3 = tf.Variable(tf.random.normal([256]))\n",
    "logit3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.sigmoid(logit3)\n",
    "\n",
    "# Layer4\n",
    "W4 = tf.Variable(tf.random.normal([256, 256]))\n",
    "b4 = tf.Variable(tf.random.normal([256]))\n",
    "logit4 = tf.matmul(layer3, W4) + b4\n",
    "layer4 = tf.nn.sigmoid(logit4)\n",
    "\n",
    "# Layer5\n",
    "W5 = tf.Variable(tf.random.normal([256, 256]))\n",
    "b5 = tf.Variable(tf.random.normal([256]))\n",
    "logit5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.sigmoid(logit5)\n",
    "\n",
    "# Layer6\n",
    "W6 = tf.Variable(tf.random.normal([256, 256]))\n",
    "b6 = tf.Variable(tf.random.normal([256]))\n",
    "logit6 = tf.matmul(layer5, W6) + b6\n",
    "layer6 = tf.nn.sigmoid(logit6)\n",
    "\n",
    "# Layer7\n",
    "W7 = tf.Variable(tf.random.normal([256, 10]))\n",
    "b7 = tf.Variable(tf.random.normal([10]))\n",
    "logit7 = tf.matmul(layer6, W7) + b7\n",
    "hypot = tf.nn.softmax(logit7)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit7, labels=y))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109f4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.644375711787829\n",
      "2 2.3343485598130647\n",
      "3 2.32778263525529\n",
      "4 2.3358328923312115\n",
      "5 2.3340866730429926\n",
      "6 2.3307320464741097\n",
      "7 2.3353698401017624\n",
      "8 2.333138206655327\n",
      "9 2.3313744709708484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26436/876235096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         _, c = sess.run([train, tf.reduce_mean(cost)], \n\u001b[1;32m---> 18\u001b[1;33m                         feed_dict={X:batch_x, y:batch_y})\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds = tf.argmax(hypot, 1)\n",
    "correct = tf.equal(preds, tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 30\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4eecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa101835",
   "metadata": {},
   "source": [
    "\n",
    "### (3) Xavier 초기화 96.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d78d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b20b9650",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_variable() got an unexpected keyword argument 'initalizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26436/2014052581.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Layer1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitalizer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlogit1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_variable() got an unexpected keyword argument 'initalizer'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 10])\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random.normal([256]))\n",
    "logit1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logit1)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random.normal([256]))\n",
    "logit2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logit2)\n",
    "\n",
    "# Layer3\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random.normal([256]))\n",
    "logit3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.sigmoid(logit3)\n",
    "\n",
    "# Layer4\n",
    "W4 = tf.get_variable(\"W4\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random.normal([256]))\n",
    "logit4 = tf.matmul(layer3, W4) + b4\n",
    "layer4 = tf.nn.sigmoid(logit4)\n",
    "\n",
    "# Layer5\n",
    "W5 = tf.get_variable(\"W5\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random.normal([256]))\n",
    "logit5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.sigmoid(logit5)\n",
    "\n",
    "# Layer6\n",
    "W6 = tf.get_variable(\"W6\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random.normal([256]))\n",
    "logit6 = tf.matmul(layer5, W6) + b6\n",
    "layer6 = tf.nn.sigmoid(logit6)\n",
    "\n",
    "# Layer7\n",
    "W7 = tf.get_variable(\"W7\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random.normal([10]))\n",
    "logit7 = tf.matmul(layer6, W7) + b7\n",
    "hypot = tf.nn.softmax(logit7)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit7, labels=y))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e70c3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26436/2091333856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         _, c = sess.run([train, tf.reduce_mean(cost)], \n\u001b[1;32m---> 18\u001b[1;33m                         feed_dict={X:batch_x, y:batch_y})\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds = tf.argmax(hypot, 1)\n",
    "correct = tf.equal(preds, tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "245df173",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/3642944499.py\", line 6, in <module>\n    prob = tf.placeholder(tf.float32)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26436/350021253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/3642944499.py\", line 6, in <module>\n    prob = tf.placeholder(tf.float32)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b2d7d",
   "metadata": {},
   "source": [
    "## (4) Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e671bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/3642944499.py:13: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_26436/3642944499.py:60: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 10])\n",
    "\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random.normal([512]))\n",
    "logit1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logit1)\n",
    "layer1 = tf.nn.dropout(layer1, keep_prob=prob)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random.normal([512]))\n",
    "logit2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logit2)\n",
    "layer2 = tf.nn.dropout(layer2, keep_prob=prob)\n",
    "\n",
    "# Layer3\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random.normal([512]))\n",
    "logit3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.sigmoid(logit3)\n",
    "layer3 = tf.nn.dropout(layer3, keep_prob=prob)\n",
    "\n",
    "# Layer4\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random.normal([512]))\n",
    "logit4 = tf.matmul(layer3, W4) + b4\n",
    "layer4 = tf.nn.sigmoid(logit4)\n",
    "layer4 = tf.nn.dropout(layer4, keep_prob=prob)\n",
    "\n",
    "# Layer5\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random.normal([512]))\n",
    "logit5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.sigmoid(logit5)\n",
    "layer5 = tf.nn.dropout(layer5, keep_prob=prob)\n",
    "\n",
    "# Layer6\n",
    "W6 = tf.get_variable(\"W6\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random.normal([512]))\n",
    "logit6 = tf.matmul(layer5, W6) + b6\n",
    "layer6 = tf.nn.sigmoid(logit6)\n",
    "layer6 = tf.nn.dropout(layer6, keep_prob=prob)\n",
    "\n",
    "# Layer7\n",
    "W7 = tf.get_variable(\"W7\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random.normal([10]))\n",
    "logit7 = tf.matmul(layer6, W7) + b7\n",
    "hypot = tf.nn.softmax(logit7)\n",
    "hypot = tf.nn.dropout(hypot, keep_prob=prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit7, labels=y))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# adamoptimizer 사용해야한다 gradientDescentOptimizer 보다... 아담이좋음..대부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f62942cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9297646102038296\n",
      "2 0.2425989585573021\n",
      "3 0.16845203516158175\n",
      "4 0.12861615558916875\n",
      "5 0.1076378992403095\n",
      "6 0.0964251663739031\n",
      "7 0.08162249476733527\n",
      "8 0.07058201642537658\n",
      "9 0.06436934723095458\n",
      "10 0.059202167296951484\n",
      "11 0.05840897542509168\n",
      "12 0.052313085220415514\n",
      "13 0.046282778903842\n",
      "14 0.04556286478584457\n",
      "15 0.04398731113919479\n",
      "16 0.04034084723754366\n",
      "17 0.037626857092096025\n",
      "18 0.035083303590389824\n",
      "19 0.035690003451467944\n",
      "20 0.029680092424492963\n",
      "21 0.032805165498178794\n",
      "22 0.031151101270859922\n",
      "23 0.02754961806307123\n",
      "24 0.028649863310750926\n",
      "25 0.027574514296667813\n",
      "26 0.02629243192728608\n",
      "27 0.024329980084757244\n",
      "28 0.026099372978152877\n",
      "29 0.023104361532975647\n",
      "30 0.021903625415870917\n",
      "31 0.02251940122445707\n",
      "32 0.020026779612843774\n",
      "33 0.020027382936413315\n",
      "34 0.018917422954268237\n",
      "35 0.019725252271905035\n",
      "36 0.020280395658178768\n",
      "37 0.02137662178180605\n",
      "38 0.0210275893076323\n",
      "39 0.018352745581545277\n",
      "40 0.018416904821060596\n",
      "41 0.01825213296635246\n",
      "42 0.01777329509622755\n",
      "43 0.017873381140472544\n",
      "44 0.016734147133855997\n",
      "45 0.014447152510243044\n",
      "46 0.01676113772375339\n",
      "47 0.015847362839638012\n",
      "48 0.01572467933938075\n",
      "49 0.015558287385554821\n",
      "50 0.017422045423776247\n"
     ]
    }
   ],
   "source": [
    "preds = tf.argmax(hypot, 1)\n",
    "correct = tf.equal(preds, tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y, prob:0.7})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55a73ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels, prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adamoptimizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc755ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
