{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39afea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "plt.rc(\"font\", family=font_name)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7x7 은 3x3이 나온다\n",
    "\n",
    "# stride 캐릭터가 이동하는 간격\n",
    "\n",
    "# padding 안에 끼워넣기 :이미 안에 끼워주기, 0으로끼워주는것, 이미지가 너무 작아지지않게하는것\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6190ae3",
   "metadata": {},
   "source": [
    "# 1.기본예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c32ef2",
   "metadata": {},
   "source": [
    "#### (1) 샘플1\n",
    "\n",
    "+ 3 * 3 * 1 * 1 이미지 준비 마지막(1)은 한장의 이미지를 가져다 쓰겠다  \n",
    "+ 2 * 2 * 1 필터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46f2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a570dba488>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array([[[[1], [2], [3]],\n",
    "                  [[4], [5], [6]],\n",
    "                  [[7], [8], [9]]]], dtype=np.float32)  # 배열로 이미지만들기 4차원\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "plt.imshow(image.reshape(3,3), cmap=\"Greys\")\n",
    "\n",
    "\n",
    "#첫번째 1 갯수 \n",
    "#네번재 1 색상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd805165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1, 1)\n",
      "(1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = tf.constant([[[[1.]], [[1]]],\n",
    "                     [[[1.]], [[1.]]]])\n",
    "\n",
    "print(filter.shape)\n",
    "\n",
    "# 1*1 2*1 4*1 5*1 =12\n",
    "\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1,1,1,1],padding=\"VALID\") # 양쪽(1,4)에 1은 크기를 맞춰주는 용도\n",
    "                                                 # 중간(2,3)번째는 이동간격 \n",
    "    \n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img,0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(one_img.reshape(2,2),cmap=\"Greys\")\n",
    "\n",
    "\n",
    "    \n",
    "# 22 가로세로 크기 ,색상수 ,갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b0c0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC6CAYAAAAQ5feLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAI3UlEQVR4nO3dX4hc9RnG8e9TYgKbRDbaREFEehHaxrYqRiGUGA1FG9sQyip45U3JiHhRU2otggUJYtQGvOpFirXgRSohIAQvJCHd/LGQuNALA6XQi1A0tjUxsTYE03TfXuzZ9OxmkjhnfjNns+/zgSHn/H4zZ98DzxzO5Mx5RxGBWTZfabsAszY4+JaSg28pOfiWkoNvKTn4llLPwZf0pKSDko5IWtdl/p+SxqvH+jJlmpW1oJcnS7oN2AisA1YAe4B7a/NLgfci4kclizQrrdcj/veAXTHlH8CnkkZr86PA6UK1mQ1Mr8FfAXxSWz8FLKutLwHWSDos6bez3hRmc8ZVT3Uk3Qu8Uq3+gZlBX0btjRARfwa+Wb1uM/Ac8PMu2+wAHYCRkZG7V65c2bD8ueXcuXNtl1DM0qVL2y6hiOPHj3Py5EnNHr9q8CPiKHA/gKRvA1uBNyWtABZExL+nnytpQURcqFY/AbomOiJ2ADsA7rzzzti7d29vezNHHTt2rO0SinnggQfaLqGI1atXdx3v6cNtRHwg6U+S/gicA54GkPQL4HfANyS9CJwHzgA/blyx2QD1FHyAiHgBeGHW2LZq8e/AdwvUZTZQvoBlKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWUqPgS9oq6YCk9yTdXhtfImln1WntbUnXlyvVrJwmLQTXAjdFxDrgCeDV2vQWYE9E3AfsBZ4sUqVZYU2O+A8COwEi4hhwQ21uPbCrWt4NrOmrOrMBaRL82d3ULkia3s6iiPhPtTy7y9pFkjqSJiRNnDp1qkEJZv1pEvzPmBnoyYiYnF6uvQlmdFmri4gdEbE6IlbfeOONDUow60+T4B8CHgGQtAr4sDZ3BNhULY8B+/qqzmxAmgT/HWChpEPAr4BnJb0saSHwEtCRNA7cDbxRrFKzgpp0Upvk0v+tebb69ySwod+izAbNF7AsJQffUnLwLSUH31Jy8C0lB99ScvAtJQffUnLwLSUH31Jy8C0lB99ScvAtJQffUnLwLSUH31Jy8C2l0g2lbpV0QtJ49VhVrlSzcnq+9bDeUErSt5hqKPVwNT0KvBURW8qVaFZe6YZSo8Dp/ssyG6yej/hcpqFUdRP6CDAm6SHgfeCZWoOpiyR1gA7AokWLeOyxxxqUMffs37+/7RKKOXr0aNslFHH27Nmu40UbSkXEuxFxB7AW+BzY3G0D9YZSCxcubFCCWX+KNpSStAAutiBxb0Cbs0o3lHpU0mFJB4C7gNcL1mpWTOmGUjurh9mc5gtYlpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWUpO+OsuBp5m6yfz52vgS4DfALcCnwOMR8a9CdZoV1eSIvx34Arhu1vgWYE9E3Afs5dLbE83mjJ6DHxGPAwe7TK0HdlXLu4E1fdRlNlAlz/EX1ZpHnWJm7x2zOaVk8CclTW9vGTO7rc0gqSNpQtLE+fPnC5Zg9uWUDP4RYFO1PAbsu9wT3UnN2tZ38GvNpF4COpLGgbuBN/rdttmgNGkaS0SMA+PV8nQzqZPAhiJVmQ2YL2BZSg6+peTgW0oOvqXk4FtKDr6l5OBbSg6+peTgW0oOvqXk4FtKDr6l5OBbSg6+peTgW0oOvqXk4FtKDr6l1HPwJS2X9KKkrbPGb5V0QtJ49VhVrkyzsprcc7sd+CswMmt8FHgrIrb0W5TZoJXspDYKnO63ILNhaNRl4TJGgDFJDwHvA8/UOqvNIKkDdABuvvlmtm3bVrCM9nz00Udtl1DMPffc03YJRSxevLjreLEPtxHxbkTcAawFPgc2X+G5FxtKjY6OlirB7EsrFnxJCwAiYpKp3plmc1bJTmqPSjos6QBwF/B639WZDUjJTmo7q4fZnOcLWJaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4llKThlKjkn5fNY06KOlrtbklknZW429Lur5suWZlNDnijwA/jYj7gZeBn9XmtgB7IuI+YC/wZN8Vmg1Ak4ZSJyLiRLV6Gjhbm14P7KqWdwNr+ivPbDAan+NLuoWpo/1rteFFtSZSp4Bll3ltR9KEpIkzZ840LcGssUbBl/RD4JfA5trRH2BS0vQ2lwGfdHu9G0pZ25p8uP0OsDEinoiI2Y2jjgCbquUxYF+f9ZkNRJO+Ot8H1koar9b/BnwMPA+8BLwp6SdMdVR+qkSRZqX1HPyIeAV45TLTJ4ENfVVkNgS+gGUpOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbyk5+JaSg28pOfiWkoNvKTn4lpKDbymVbih1q6QT1dy4pFVlyzUro8k9t9MNpU5I+gFTLUam760dBd6KiC2F6jMbiCb33NbbicxuKDVajZnNaaUbSo0AY5Lek/SapOv6rM9sIBQRvb9oqqHURuC5Lr11qJpKvQB8HBG/7jLfATrV6teBv/RcRG++ylQHiPlgvuzLsPbjtohYPnuw51OdekOpLnMLIuJCRExKuuQNMS0idgA7ev3bTUmaiIjVw/p7gzRf9qXt/SjdUGpM0lPAf4Hj/P+objanNDrVuda0fXQpab7sS9v7keUC1tBOq4ZgvuxLq/uR4ohvNluWI77ZDPM++JK2SjpQXVu4ve16mpK0XNKLkra2XUs/rvSVl2Ga18GXtBa4KSLWAU8Ar7ZcUj+2A18A1/pFwSv9htrQzOvgAw8COwEi4hhwQ7vlNBcRjwMH266jX1f5DbWhme/BX8HMnyO6UPupImvRZb7yMjRNLmBdSz5j5g/QTUbEZFvF2JTaV142d/vKyzDM96PfIeARgOregA/bLceu8htqQzPfj/jvAA9LOgR8ztQHXGvXJV95qT6/DJUvYFlK8/1Ux6wrB99ScvAtJQffUnLwLSUH31Jy8C0lB99S+h+XKWgbqBsmVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = tf.constant([[[[1.]], [[1]]],\n",
    "                     [[[1.]], [[1.]]]])\n",
    "\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1,1,1,1],padding=\"SAME\") # 양쪽(1,4)에 1은 크기를 맞춰주는 용도\n",
    "                                                 # 중간(2,3)번째는 이동간격 \n",
    "# SAME는 패딩을 하겠다.\n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img,0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(one_img.reshape(3,3),cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56d9cc",
   "metadata": {},
   "source": [
    "+ 3 개의 필터 사용 2 *2* 1*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28766ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1, 3)\n",
      "(1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = tf.constant([[[[1.,10,-1]], [[1.,10,-1]]],\n",
    "                     [[[1., 10, -1]], [[1.,10,-1]]]])\n",
    "print(filter.shape)\n",
    "\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1,1,1,1],padding=\"SAME\") # 양쪽(1,4)에 1은 크기를 맞춰주는 용도\n",
    "                                                 # 중간(2,3)번째는 이동간격 \n",
    "# SAME는 패딩을 하겠다.\n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape) # 색상수 1, 3x3 크기 ,갯수3\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img,0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(one_img.reshape(3,3),cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b40cf",
   "metadata": {},
   "source": [
    "+ MaxPooling : 2 * 2 필터\n",
    "+ padding 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676761c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "(1, 1, 1, 1)\n",
      "[[[[4]]]]\n"
     ]
    }
   ],
   "source": [
    "image2 =tf.constant([[[[4],[3]],\n",
    "                     [[2],[1]]]])\n",
    "print(image2.shape)\n",
    "\n",
    "pool =tf.nn.max_pool(image2, ksize=[1,2,2,1],strides=[1,1,1,1],padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c916de63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "(1, 2, 2, 1)\n",
      "[[[[4]\n",
      "   [3]]\n",
      "\n",
      "  [[2]\n",
      "   [1]]]]\n"
     ]
    }
   ],
   "source": [
    "image2 =tf.constant([[[[4],[3]],\n",
    "                     [[2],[1]]]])\n",
    "print(image2.shape)\n",
    "\n",
    "pool =tf.nn.max_pool(image2, ksize=[1,2,2,1],strides=[1,1,1,1],padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)\n",
    "\n",
    "# 최대값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76208410",
   "metadata": {},
   "source": [
    "### 2. 응용 예제 1: MNIST 를 이용한 Simple CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10c87a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_29240/1748856294.py:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data1/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data1/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data1/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data1/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data1/mnist/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff36a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a575a30648>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 데이터 확인\n",
    "\n",
    "img = mnist.train.images[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1f59e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_23200/3898449982.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\김정호\\AppData\\Local\\Temp/ipykernel_23200/3898449982.py:3: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb182040",
   "metadata": {},
   "source": [
    "# Simple CNN 특징 추출단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82019aad",
   "metadata": {},
   "source": [
    "## (1) 첫번째 Convolution Layer\n",
    "\n",
    "+ 필터\n",
    "    - 크기: 3* 3 \n",
    "    - 갯수: 32\n",
    "    - 색상수 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f08d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_8:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu_8:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 원본 이미지 준비\n",
    "\n",
    "\n",
    "origin_X = tf.reshape(X,[-1,28,28,1])\n",
    "\n",
    "# 필터(가중치) 준비\n",
    "\n",
    "W1= tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "\n",
    "# Convolution Layer : stride 1칸 ,패딩 있음\n",
    "layer1 =tf.nn.conv2d(origin_X,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "print(layer1)\n",
    "\n",
    "layer1 = tf.nn.relu(layer1)\n",
    "print(layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47e831",
   "metadata": {},
   "source": [
    "## (2) 첫번째 pooling\n",
    "\n",
    "+ 필터 크키: 2 * 2\n",
    "    \n",
    "+ stride : 2\n",
    "    \n",
    "+ paddin 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b31301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_11:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer1 = tf.nn.max_pool(layer1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "print(layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa76b8c",
   "metadata": {},
   "source": [
    "### 3. 두 번째 Convolution Layer\n",
    "\n",
    "+ 필터\n",
    "    - 크기 : 3* 3\n",
    "    - 갯수 : 64\n",
    "    - 색상수 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "101cb892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_9:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_9:0\", shape=(?, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 필터 준비\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "\n",
    "# convolution layer\n",
    "\n",
    "layer2 =tf.nn.conv2d(layer1,W2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "print(layer2)\n",
    "\n",
    "layer2 = tf.nn.relu(layer2)\n",
    "print(layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4def0a3",
   "metadata": {},
   "source": [
    "# (4) 두번째 pooling\n",
    "\n",
    "+ 필터 크기 : 2*2\n",
    "+ stride : 2\n",
    "+ padding 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6e77980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_12:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer2 = tf.nn.max_pool(layer2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "print(layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07d974",
   "metadata": {},
   "source": [
    "### (5) FC(Fully Connected) Layer: Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fa86bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9980119953101331\n",
      "2 0.2257094240324064\n",
      "3 0.17503473995761445\n",
      "4 0.13382488854906774\n",
      "5 0.1217837003144351\n",
      "6 0.10411829809573561\n",
      "7 0.09754950780082831\n",
      "8 0.08761713504791263\n",
      "9 0.07534534616226501\n",
      "10 0.07099316106601196\n",
      "11 0.065035050413148\n",
      "12 0.058735820515589274\n",
      "13 0.05294392259622164\n",
      "14 0.04697312053970316\n",
      "15 0.04988651723516259\n",
      "16 0.04270406455986879\n",
      "17 0.03893456998365845\n",
      "18 0.03178631013936617\n",
      "19 0.029958427684720255\n",
      "20 0.029916667675768786\n"
     ]
    }
   ],
   "source": [
    "### Hyper Parameter 준비\n",
    "\n",
    "lr = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "####### Tensorflow Grapn\n",
    "\n",
    "train_X = tf.reshape(layer2,[-1,7*7*64])\n",
    "\n",
    "W= tf.Variable(tf.random_normal([7*7*64,10]))\n",
    "b= tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "\n",
    "# 비용\n",
    "\n",
    "logit = tf.matmul(train_X,W)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,labels=y))\n",
    "\n",
    "# 최저 비용\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "##### Tensor Graph 실행\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "878ce597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tf.argmax(logit, 1)\n",
    "correct = tf.equal(preds,tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "\n",
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe510c65",
   "metadata": {},
   "source": [
    "### (6) Deep & Wide FC\n",
    "\n",
    "+ 레이어는 총 3개 사용, 입출력 갯수는 128개 사용\n",
    "+ Xavier 초기화 사용\n",
    "+ dropout 사용(70%)\n",
    "+ traing_epcochs : 15\n",
    "+ batch_size: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "251a1231",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23200/3092929239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Layer1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlogit1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1243\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[1;32m--> 868\u001b[1;33m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "##### Hyper Parameter 준비\n",
    "lr = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "##### Tensorflow Graph\n",
    "train_X = tf.reshape(layer2, [-1, 7*7*64])\n",
    "\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.get_variable(\"W1\", shape=[7*7*64, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([128]))\n",
    "logit1 = tf.matmul(train_X, W1) + b1\n",
    "train_X = tf.nn.relu(logit1)\n",
    "l1 = tf.nn.dropout(train_X, keep_prob=prob)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.get_variable(\"W2\", shape=[128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([128]))\n",
    "logit2 = tf.matmul(l1, W2) + b2\n",
    "l2 = tf.nn.relu(logit2)\n",
    "l2 = tf.nn.dropout(l2, keep_prob=prob)\n",
    "\n",
    "# Layer3\n",
    "W_out = tf.get_variable(\"W_out\", shape=[128, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_out = tf.Variable(tf.random_normal([10]))\n",
    "logit = tf.matmul(l2, W_out) + b_out\n",
    "\n",
    "# 비용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y))\n",
    "\n",
    "# 최저 비용\n",
    "train = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "##### Tensor Graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], \n",
    "                        feed_dict={X:batch_x, y:batch_y, prob:0.7})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(epoch+1, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a542c073",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"Users\\김정호\\AppData\\Local\\Temp/ipykernel_23200/3092929239.py\", line 5, in <module>\n    prob = tf.placeholder(tf.float32)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23200/3595089481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"anaconda3\\envs\\tf1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"anaconda3\\envs\\tf1\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"Users\\김정호\\AppData\\Local\\Temp/ipykernel_23200/3092929239.py\", line 5, in <module>\n    prob = tf.placeholder(tf.float32)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "preds = tf.argmax(logit, 1)\n",
    "correct = tf.equal(preds,tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "\n",
    "sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels,prob:1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf206be0",
   "metadata": {},
   "source": [
    "## 3. 응용 예제 2: 교통 표지판을 이용한 CNN\n",
    "\n",
    "+ https://benchmark.ini.rub.de/gtsrb_dataset.html\n",
    "\n",
    " - GTSRB_Final_Test_Image.zip\n",
    " \n",
    "+ Simple CNN\n",
    "\n",
    " - 이미지 (32* 32) -> Conv Layer1(Pooling) -> Conv Layer2(Pooling) -> FC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fdcce",
   "metadata": {},
   "source": [
    "### (1) 이미지 전처리와 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.color import rgb2lab # 컬러에 색상을 빼주는 객체\n",
    "from skimage.transform import resize # 크기변환\n",
    "from collections import namedtuple # 이름\n",
    "np.random.seed(101) # 101 난수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67325fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 상수 정의\n",
    "\n",
    "N_CLASSES = 43 # 43대신에 N_클래스를 대신씀. # 43개의 교통표지판\n",
    "RESIZED_IMAGE =(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e514da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값의 수정을 방지하기 위해\n",
    "Dataset =namedtuple(\"Dataset\",[\"X\",\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b40ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 1)\n",
      "(39209, 43)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##### 이미지 크기 재조정하고 색상은 회색조로 변경, one-hot encoding\n",
    "\n",
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n",
    "\n",
    "def read_ppm(data1, n_labels, resize_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for c in range(n_labels):\n",
    "        full_path = data1 + \"/\" + format(c, '05d') + \"/\"\n",
    "        \n",
    "        for img_name in glob.glob(full_path + \"*.ppm\"):\n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "\n",
    "            img = rgb2lab(img/255.0)[:, :, 0]\n",
    "            \n",
    "            img = resize(img, resize_to, mode=\"reflect\")\n",
    "            \n",
    "            label = np.zeros((n_labels,), dtype=np.float32)\n",
    "            label[c] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "            \n",
    "    return Dataset(X=to_tf_format(images), y=np.array(labels))\n",
    "# --------------------------------------------------\n",
    "\n",
    "ds = read_ppm(\"data1/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images\", N_CLASSES, RESIZED_IMAGE)\n",
    "print(ds.X.shape)\n",
    "print(ds.y.shape)\n",
    "\n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10  용량 많을때 이렇게킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4050721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4만개...정도 나옴 색상수 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a287f2ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### 전처리된 이미지 확인\n",
    "\n",
    "plt.imshow(ds.X[0,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[0,:])\n",
    "\n",
    "plt.imshow(ds.X[-1,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[-1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21fd5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29406\n",
      "[271, 23055, 34387, 28229, 26437, 3760, 30266, 11625, 24743, 6505]\n",
      "(29406, 32, 32, 1)\n",
      "(9803, 32, 32, 1)\n",
      "(29406, 43)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "##### 훈련 데이터와 테스트 데이터의 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(range(ds.X.shape[0]), ds.y, test_size=0.25,\n",
    "#                                                    random_state=101)\n",
    "# print(len(X_train), len(X_test))\n",
    "# type(X_train)\n",
    "# np.array(X_train).shape\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(ds.X.shape[0]), test_size=0.25, random_state=101)\n",
    "print(len(idx_train))\n",
    "print(idx_train[:10])\n",
    "\n",
    "X_train = ds.X[idx_train, :, :, :]\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = ds.X[idx_test, :, :, :]\n",
    "print(X_test.shape)\n",
    "\n",
    "y_train = ds.y[idx_train, :]\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = ds.y[idx_test, :]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44cff9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 39209)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(ds.X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dedaa6",
   "metadata": {},
   "source": [
    "### (2) 훈련을 위한 함수 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b89c906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 미니 배치 준비\n",
    "\n",
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        idx = list(range(n_samples))\n",
    "        \n",
    "    for i in range(int(np.ceil(n_samples/batch_size))):\n",
    "        from_idx = i * batch_size\n",
    "        to_idx = (i+1) * batch_size\n",
    "        \n",
    "        yield  X[idx[from_idx:to_idx], :, :, :], y[idx[from_idx:to_idx], :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cc3b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "##### 미니 배치 테스트 코드\n",
    "for i in minibatcher(X_train, y_train, 10000, True):\n",
    "    print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e376dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_no_activation_layer(in_tensors, n_units):\n",
    "    W = tf.get_variable(\"fc_W\", [in_tensors.get_shape()[1], n_units], \n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"fc_b\", [n_units], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.matmul(in_tensors, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f3b91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(in_tensors, n_units):\n",
    "    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ba18b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size, kernel_size, in_tensors.get_shape()[3], n_units], \n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"conv_b\", [n_units], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    conv = tf.nn.conv2d(in_tensors, W, [1, 1, 1, 1], \"SAME\")\n",
    "    \n",
    "    return tf.nn.leaky_relu(conv + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73ae019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\",[kernel_size,kernel_size,in_tensors.get_shape()[3],n_units],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"conv_b\",[n_unit],initializer=tf.constant_initializer(0,0))\n",
    "    \n",
    "    conv =tf.nn.conv2d(in_tensors,W,[1,1,1,1],\"SAME\")\n",
    "    \n",
    "    return tf.nn.leaky_relu(conv+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8159c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(in_tensors, sampling):\n",
    "    return tf.nn.max_pool(in_tensors, [1, sampling, sampling, 1], \n",
    "                          [1, sampling, sampling, 1], \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e095424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(in_tensors, keep_proba, is_training):\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors, keep_proba), lambda:in_tensors) #조건문을 써주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f2b2c",
   "metadata": {},
   "source": [
    "### (3) Model 구현\n",
    "\n",
    "+ Specification\n",
    "    - 2차원 Convolution 5* 5, 32 필터\n",
    "    - 2차원 Convolution 5* 5, 64 필터\n",
    "    - 평면화 계층 (Flat Layer)\n",
    "    - Full Connected Layer, 1024개의 unit\n",
    "    - dropout 40%\n",
    "    - softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e3dbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(in_tensors, is_training):\n",
    "    # First Layer : 5*5 2d convolution layer, 32 filter, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n",
    "        l1_out = dropout(l1, 0.8, is_training)\n",
    "        \n",
    "    # Second Layer : 5*5 2d convolution layer, 64 filter, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(l1_out, 5, 64), 2)\n",
    "        l2_out = dropout(l2, 0.8, is_training)\n",
    "        \n",
    "    # Flat Layer\n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out)\n",
    "        \n",
    "    # FC Layer, 1024 neurons, 40% dropout\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, 1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "        \n",
    "    # out\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        out_tensors = fc_no_activation_layer(l3_out, N_CLASSES)\n",
    "        \n",
    "    return out_tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e70bea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def train_model(X_train, y_train, lr, max_epochs, batch_size):\n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None, RESIZED_IMAGE[0], \n",
    "                                                           RESIZED_IMAGE[1], 1))\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape=(None, N_CLASSES))\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    logit = model(in_X_tensors_batch, is_training)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, \n",
    "                                                                    labels=in_y_tensors_batch))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(\"Epoch=\", epoch)\n",
    "            tf_scores = []\n",
    "            \n",
    "            for mb in minibatcher(X_train, y_train, batch_size, shuffle=True):\n",
    "                _, c = sess.run([train, cost], feed_dict={in_X_tensors_batch:mb[0],\n",
    "                                                         in_y_tensors_batch:mb[1],\n",
    "                                                         is_training:True})\n",
    "                tf_scores.append(c)\n",
    "                \n",
    "            print(\"train loss score=\", np.mean(tf_scores))\n",
    "            \n",
    "        # 훈련이 끝나고 난 후 테스트\n",
    "        print(\"TEST SET PERFORMANCE\")\n",
    "        \n",
    "        out_y_pred = tf.nn.softmax(logit)\n",
    "        y_test_pred, test_cost = sess.run([out_y_pred, cost], feed_dict={in_X_tensors_batch:X_test,\n",
    "                                                         in_y_tensors_batch:y_test,\n",
    "                                                         is_training:False})\n",
    "        \n",
    "        print(\"test_loss_score=\", test_cost)\n",
    "        y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n",
    "        y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n",
    "        print(classification_report(y_test_true_classified, y_test_pred_classified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0e611a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_unit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29240/352430883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## 99프로 이상이 나옴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29240/1893671115.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, lr, max_epochs, batch_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_X_tensors_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, \n\u001b[0;32m     11\u001b[0m                                                                     labels=in_y_tensors_batch))\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29240/3841802856.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(in_tensors, is_training)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# First Layer : 5*5 2d convolution layer, 32 filter, 2x maxpool, 20% dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"L1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxpool_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0ml1_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29240/2558102138.py\u001b[0m in \u001b[0;36mconv_layer\u001b[1;34m(in_tensors, kernel_size, n_units)\u001b[0m\n\u001b[0;32m      3\u001b[0m                        initializer=tf.contrib.layers.xavier_initializer())\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_unit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_unit' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, 0.001, 10, 256)\n",
    "\n",
    "## 99프로 이상이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "346e9fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 일부 CNN 계층과 FC계층을 추가해서 성능이 어떻게 변하는지 확인\\n2. dropout의 비율을 변경해 보면서 결과가 과소적합 또는 과대적합이 되는지 확인\\n3. 전체 epoch수와 batch_size도 변경해서 결과 확인\\n4. 실제 테스트 이미지를 통해 사용 할 수 있는 간단한 프로그램 작성\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. 일부 CNN 계층과 FC계층을 추가해서 성능이 어떻게 변하는지 확인\n",
    "2. dropout의 비율을 변경해 보면서 결과가 과소적합 또는 과대적합이 되는지 확인\n",
    "3. 전체 epoch수와 batch_size도 변경해서 결과 확인\n",
    "4. 실제 테스트 이미지를 통해 사용 할 수 있는 간단한 프로그램 작성\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92596aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
